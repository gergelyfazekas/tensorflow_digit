{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "991325a3",
   "metadata": {},
   "source": [
    "## Handwritten Digit Classification\n",
    "#### Application of a Tensorflow sequential neural network on the MNIST dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa108999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gergelyfazekas/miniforge3/lib/python3.10/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.11) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5511bdd5",
   "metadata": {},
   "source": [
    "### Defining functions to convert the kaggle dataset to suitable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74ef7481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_grayscale(df):\n",
    "    \"\"\"reverses grayscale values so that 0 is black and 255 is white\"\"\"\n",
    "    # Lambda func: \n",
    "    reverse_color = np.vectorize(lambda x: 255-x)\n",
    "    \n",
    "    # Stripping labels\n",
    "    without_label = df.iloc[:,1:]\n",
    "    \n",
    "    # Applying reverse_color row-wise\n",
    "    new_colors_df = without_label.apply(reverse_color, axis=0)\n",
    "    \n",
    "    # Reassign label\n",
    "    new_colors_df['label'] = df['label']\n",
    "    \n",
    "    return new_colors_df\n",
    "\n",
    "def df_to_array(df):\n",
    "    \"\"\"turns the images' representation from pd.DataFrame to np.array\n",
    "    returns a dictionary: key = img id, value = [label, np.array]\n",
    "    \"\"\"\n",
    "    \n",
    "    def convert_to_img_array(df_row):\n",
    "        \"\"\"converts one row of df into a 28x28 np array that represents the image\"\"\"\n",
    "        # Stack rows in a list of lists\n",
    "        img_rows = []\n",
    "        for i in range(28):\n",
    "            img_rows.append(df_row.iloc[28*i:(28*i+28)])\n",
    "        # Convert to np.array\n",
    "        pic_array = np.array(img_rows)\n",
    "        return pic_array\n",
    "    \n",
    "    # Create a dictionary of images: key=id, value=(label, np.array)\n",
    "    result = dict(zip(list(df.index) , [list(item) for item in list(zip(df['label'], [None]* len(df['label'])))]))\n",
    "    \n",
    "    # Apply convert_to_img_array row_wise\n",
    "    for row in df.iterrows():\n",
    "        # iterrows returns a tuple of (index, row series) -- we need both\n",
    "        image = convert_to_img_array(row[1])\n",
    "        result[row[0]][1] = image\n",
    "        \n",
    "    return result\n",
    "\n",
    "def train_test_split(input_dict, ratio=0.8):\n",
    "    d = input_dict.copy()\n",
    "    test_size = round((1-ratio) * len(list(d.keys())))\n",
    "    test_set_keys = list(np.random.choice(list(d.keys()), size=test_size, replace=False))\n",
    "    \n",
    "    test = {}\n",
    "    for k in test_set_keys:\n",
    "        test[k] = d[k]\n",
    "        d.pop(k)\n",
    "        \n",
    "    train = d.copy()\n",
    "    \n",
    "    train_list = list(train.values())\n",
    "    test_list =list(test.values())\n",
    "    \n",
    "    y_train, X_train = [item[0] for item in train_list], [item[1] for item in train_list]\n",
    "    y_test, X_test = [item[0] for item in test_list], [item[1] for item in test_list]\n",
    "    \n",
    "    return (np.array(X_train), np.array(y_train)), (np.array(X_test), np.array(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fb273b",
   "metadata": {},
   "source": [
    "### 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f3f4ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8dc7fe",
   "metadata": {},
   "source": [
    "### 2. Preprocessing colors shapes and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5c710c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reversed = reverse_grayscale(mnist)\n",
    "img_dict = df_to_array(df_reversed)\n",
    "\n",
    "# Normalize grayscale values\n",
    "for k in img_dict.keys(): \n",
    "    img_dict[k][1] = tf.keras.utils.normalize(img_dict[k][1], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a535e0",
   "metadata": {},
   "source": [
    "### 3. Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a736083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = train_test_split(img_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684b4042",
   "metadata": {},
   "source": [
    "### 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39e59185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 19:11:25.688612: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-01-16 19:11:25.689212: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fa1f34",
   "metadata": {},
   "source": [
    "### 5. Fitting and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c2e803c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  25/1050 [..............................] - ETA: 4s - loss: 0.3359 - accuracy: 0.8900"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 19:13:27.094676: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 5s 4ms/step - loss: 0.2794 - accuracy: 0.9145\n",
      "Epoch 2/10\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.2412 - accuracy: 0.9252\n",
      "Epoch 3/10\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.2093 - accuracy: 0.9362\n",
      "Epoch 4/10\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1915 - accuracy: 0.9402\n",
      "Epoch 5/10\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1716 - accuracy: 0.9465\n",
      "Epoch 6/10\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1592 - accuracy: 0.9505\n",
      "Epoch 7/10\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1446 - accuracy: 0.9555\n",
      "Epoch 8/10\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1368 - accuracy: 0.9575\n",
      "Epoch 9/10\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1307 - accuracy: 0.9599\n",
      "Epoch 10/10\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1196 - accuracy: 0.9626\n",
      "INFO:tensorflow:Assets written to: handwritten_NN/assets\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "model.save('handwritten_NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "984456fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('handwritten_NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f462689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27/263 [==>...........................] - ETA: 0s - loss: 0.1398 - accuracy: 0.9583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 19:14:17.900895: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 1s 4ms/step - loss: 0.1236 - accuracy: 0.9635\n",
      " \n",
      "Loss:  0.124 -- Accuracy:  0.963\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\" \")\n",
    "print(\"Loss: \", round(loss,3), \"--\", \"Accuracy: \", round(accuracy,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcf115e",
   "metadata": {},
   "source": [
    "### Testing visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c8b871e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      " \n",
      "Number detected:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select and image randomly from the test set\n",
    "rand_int = np.random.randint(0,8399,1)[0]\n",
    "random_image = X_test[rand_int : rand_int+1]\n",
    "\n",
    "# Predict the class probabilities and the label\n",
    "predicted_probabilities = model.predict(random_image)\n",
    "predicted_label = np.argmax(predicted_probabilities)\n",
    "\n",
    "# Show\n",
    "plt.imshow(random_image[0], cmap=plt.cm.binary)\n",
    "print(\" \")\n",
    "print(\"Number detected: \", predicted_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
